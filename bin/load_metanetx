#! /usr/bin/env python
# -*- coding: utf-8 -*-

"""Load synonyms from MetaNetX MNXref namespace."""

from ome.base import *
from ome.models import *
from ome.components import *
from ome.util import get_or_create, get_or_create_data_source

from sqlalchemy import exists
from os.path import join, abspath, dirname, exists
from os import mkdir
import subprocess
from collections import defaultdict

# MetaNetX files to download
files = {
    'chem_xref': 'chem_xref.tsv',
    # XREF <tab> MNX_ID <tab> Evidence <tab> Description
    # bigg:10fthf <tab> MNXM237 <tab> inferred <tab> 10-Formyltetrahydrofolate

    # 'chem_prop': 'chem_prop.tsv',
    # MNX_ID <tab> Description <tab> Formula <tab> Charge <tab> Mass <tab> InChi <tab> SMILES <tab> Source

    'comp_xref': 'comp_xref.tsv',
    # XREF <tab> MNX_ID <tab> Description

    # 'comp_prop': 'comp_prop.tsv',
    # MNX_ID <tab> Description <tab> Source

    'reac_xref': 'reac_xref.tsv',
    # XREF <tab> MNX_ID
    # bigg:10FTHF5GLUtl <tab> MNXR1

    'reac_prop': 'reac_prop.tsv',
    # MNX_ID <tab> Equation <tab> Description <tab> Balance <tab> EC <tab> Source
}

# translation table for MetaNetX databases to those already in BiGG Models
# see https://github.com/SBRG/bigg_models_data/blob/master/data-source-prefs.txt
db_translation = {
    'metabolite': {
        'biopath': 'biopath.molecule',
        'chebi': lambda val: ('chebi', 'CHEBI:%s' % val),
        'kegg': lambda val: ('kegg.drug', val) if val.startswith('D') else ('kegg.compound', val),
        'metacyc': lambda val: ('biocyc', 'META:%s' % val),
        'seed': 'seed.compound',
        'umbbd': 'umbbd.compound',
        'upa': 'unipathway.compound',
    },
    'reaction': {
        'biopath': 'biopath.reaction',
        'kegg': 'kegg.reaction',
        'metacyc': lambda x: ('biocyc', 'META:%s' % x),
        'reactome': lambda x: ('reactome', 'REACT_%s' % x),
        # 'seed': # could not find a good url prefix for seed reactions
        'upa': 'unipathway.reaction',
    },
}

# directory to store the MetaNetX files
data_dir = abspath(join(dirname(__file__), '..', 'temp_data'))

# make the temp directory
try:
    mkdir(data_dir)
except OSError:
    pass


def main():
    # download the files from MetaNetX
    for key, filename in files.iteritems():
        download_file(filename)

    # database session
    session = Session()

    # Update chemicals
    update_synonyms(parse_xref('chem_xref', 'metabolite'), 'metabolite', session)

    # Update reactions
    reaction_xref = parse_xref('reac_xref', 'reaction')
    reaction_xref = add_ec_numbers('reac_prop', reaction_xref)
    update_synonyms(reaction_xref, 'reaction', session)

    # Update compartments
    # TODO compartment synonyms

    print_missing_metabolite_refs(session)

    session.close()


def add_prefix(loc):
    """Add the MetaNetX url prefix."""
    return 'http://www.metanetx.org/cgi-bin/mnxget/mnxref/%s' % loc.lstrip('/')


def download_file(filename):
    """Download a file to the data dir."""
    destination = join(data_dir, filename)
    if not exists(destination):
        print('Downloading %s' % filename)
        subprocess.call(['wget', '-O', destination, add_prefix(filename)])
    else:
        print('Already downloaded %s' % filename)


def update_synonyms(xref_dict, ref_type, session):
    """Use MetaNetX files to add Reaction or Metabolite synonyms."""

    warned = set()

    stats = { 'found': 0,
              'not_found': 0 }

    object_class = Reaction if ref_type == 'reaction' else Component
    object_synonym_type = 'reaction' if ref_type == 'reaction' else 'component'

    for bigg_id, ref_dict in xref_dict.iteritems():
        # look for the metabolites
        objects_db = (session
                        .query(object_class)
                        .filter(object_class.bigg_id == bigg_id))
        if objects_db is None:
            # check old IDs
            if ref_type == 'reaction':
                objects_db = (session
                              .query(object_class)
                              .join(ModelReaction)
                              .join(OldIDSynonym, OldIDSynonym.ome_id == ModelReaction.id)
                              .join(Synonym)
                              .filter(Synonym.synonym == bigg_id))
            else:
                objects_db = (session
                              .query(object_class)
                              .join(CompartmentalizedComponent)
                              .join(ModelCompartmentalizedComponent)
                              .join(OldIDSynonym, OldIDSynonym.ome_id == ModelCompartmentalizedComponent.id)
                              .join(Synonym)
                              .filter(Synonym.synonym == bigg_id))
            if objects_db.count() == 0:
                print('%s not found in database: %s' % (ref_type, bigg_id))
                continue
            # else:
            #     print(bigg_id, objects_db.first().bigg_id)

        if objects_db.count() > 1:
            print('Multiple results for %s: %s' % (ref_type, bigg_id))

        for object_db in objects_db:
            for ref, values in ref_dict.iteritems():
                data_source_id = get_or_create_data_source(session, ref)

                for val in values:
                    # add the Synonym
                    synonym_db, exists = get_or_create(session, Synonym,
                                                       ome_id=object_db.id,
                                                       type=object_synonym_type,
                                                       data_source_id=data_source_id,
                                                       synonym=val)
                    if exists: stats['found'] += 1
                    else: stats['not_found'] += 1

    print('New %s synonyms: %d' % (ref_type, stats['not_found']))


def add_ec_numbers(file_key, reaction_xref):
    """Add EC numbers from the reaction properties file to the xref object.

    """

    # read the file
    ec_numbers = {}
    with open(join(data_dir, files[file_key]), 'r')  as f:
        for line in f.readlines():
            if line.strip().startswith('#') or line.strip() == '':
                continue
            split_line = [x.strip() for x in line.split('\t')]
            # no ec number
            if split_line[4].strip() == '':
                continue
            for ec in [x.strip() for x in split_line[4].split(';')]:
                # ec_numbers[MNX_ID] = EC
                ec_numbers[split_line[0]] = ec

    for bigg_id, val in reaction_xref.iteritems():
        if not 'mnx.equation' in val:
            continue
        for mnx_id in val['mnx.equation']:
            if not mnx_id in ec_numbers:
                continue
            if not 'ec' in val:
                val['ec'] = []
            val['ec'].append(ec_numbers[mnx_id])

    return reaction_xref

def parse_xref(file_key, ref_type):
    """Read an xref file and generate a dict like this:

    { bigg_id: { external_db_tranlated: [values] } }

    """

    bigg_to_metanetx = {}
    metanetx_to_ref = defaultdict(lambda: defaultdict(list))

    # read the file
    with open(join(data_dir, files[file_key]), 'r')  as f:
        for line in f.readlines():
            if line.strip().startswith('#') or line.strip() == '':
                continue
            split_line = [x.strip() for x in line.split('\t')]
            strip_line = [x.strip() for x in split_line[0].split(':', 1)]
            try:
                ref, val = strip_line[:2]
            except:
                continue
            if ref == 'bigg':
                bigg_to_metanetx[val] = split_line[1]
            else:
                # look for the db in the translation dict
                trans = db_translation[ref_type].get(ref, None)
                if trans is None:
                    # no translation
                    ref_tr = ref
                elif hasattr(trans, '__call__'):
                    # if it's a function
                    ref_tr, val = trans(val)
                else:
                    # translation
                    ref_tr = trans
                metanetx_to_ref[split_line[1]][ref_tr].append(val)

    # make the dictionary and add metanetx ref
    mnx_ref_id = 'mnx.chemical' if ref_type == 'metabolite' else 'mnx.equation'
    return { bigg: dict(metanetx_to_ref[mnx], **{ mnx_ref_id: [mnx] })
             for bigg, mnx in bigg_to_metanetx.iteritems() }

def print_missing_metabolite_refs(session):
    """Print any metabolites with no external database ID, by model."""
    print('Looking for metabolites with no linkout')
    mets_with_source_db = (session
                           .query(Component.id)
                           .join(Synonym, Synonym.ome_id == Component.id)
                           .join(DataSource, DataSource.id == Synonym.data_source_id)
                           .filter(DataSource.url_prefix is not None)
                           .filter(DataSource.name != 'mnx.chemical'))
    mets_no_source_db = (session
                         .query(Model.bigg_id, Component.bigg_id)
                         .join(ModelCompartmentalizedComponent, ModelCompartmentalizedComponent.model_id == Model.id)
                         .join(CompartmentalizedComponent, CompartmentalizedComponent.id == ModelCompartmentalizedComponent.compartmentalized_component_id)
                         .join(Component, Component.id == CompartmentalizedComponent.component_id)
                         .filter(~Component.id.in_(mets_with_source_db))
                         .order_by(Model.bigg_id))
    by_model = defaultdict(list)
    for model_bigg_id, met_bigg_id in mets_no_source_db:
        by_model[model_bigg_id].append(met_bigg_id)
    for model_bigg_id, l in by_model.iteritems():
        print('Warning: Metabolites with no linkout in model %s' % model_bigg_id)
        print(', '.join(l))
    print('Finished')

if __name__ == '__main__':
    main()
